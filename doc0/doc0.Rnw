\documentclass[fleqn]{article}

%\usepackage[spanish,activeacute]{babel}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{float}
\usepackage{cancel}
\restylefloat{table}

\usepackage{multirow}
\usepackage{eurosym}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{array}
%\usepackage[cmex10]{amsmath}
\usepackage[english]{babel}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[lofdepth,lotdepth]{subfig}
\usepackage{lscape}
\setlength\parindent{0pt}
\usepackage{framed, color}
\usepackage{color}
\usepackage[showframe=false]{geometry}
\usepackage{changepage}


\begin{document}

\SweaveOpts{concordance=TRUE}

\title{Simulating and fitting presence-absence response curves }
\title{%
  Simulating and fitting presence-absence response curves \\
  \large Ideas and preliminary work}

%\author{L. Citores, ...}

\maketitle

\tableofcontents
\newpage

<<echo=F, message=FALSE, warning=FALSE, eval=T>>=
library(coenocliner)
library(plotrix)
library(scam)
library(plotmo)
library(ggplot2)
library(marmap)
library(lattice)
library(reshape2)

@


\section {Introduction}

The objective is to see how different methods perform when fitting presence-absence response curves inside the ecological niche theory framework.\\

Most commonly used methods are GLMs (Coudun etal. 2006, Jamil etal. 2013) and GAMs (Austin 2002, Heikkinen etal 2010). Logistic regression (GLM with logit link) can result too restrictive as response curves are restricted to be symmetric. GAMs are very flexible to adjust non symmetric shapes but can result in non plausible shapes, not in concordance with the ecological niche theory (lack of unimodality).\\

Shape constrained Generalized Additive Models (Pya etal. 2014) can represent an effective alternative as they can adjust non symmetric shapes while keeping the unimodality constrains that is claimed by the ecological niche theory. The "scam" package will be used to fit these models.\\

Other approaches could be studied as well, such as the Bayesian envelope approach by Brewer etal. 2016. HOF curves are another alternative used in some areas (Huisman etal. 1993, Michaelis etal. 2017).\\

\section {Simulation}

To test the performance of different methods a simulation study is proposed. The idea is to simulate different plausible presence-absence data sets related to a single environmental variable (to start with). These simulated data sets will be fitted with the most commonly used methods and will be compared to the scam fitting.\\

\subsection {Beta shape curves}

As proposed in Minchin 1987 the beta function (1) seems to be a good option to simulates species abundance along a environmental gradient.

 \begin{eqnarray}
 &&f(x,A0,m,r,\alpha,\gamma)=\left\{
                \begin{array}{ll}
                    \frac{A0}{d}  \left(\frac{x-m}{r} +b\right) ^\alpha \left(1-(\frac{x-m}{r}+b\right)^\gamma & \quad m-rb<x<m+r(1-b)\\
                    \\
                  0 & \quad \text{otherwise}
                \end{array}
              \right.
 \end{eqnarray} 
 
 where, $m$ is the location at optima or mode, $A0$ is the maximum abundance at the mode, $r$ is the range of occurrence along the gradient and $\alpha$ and $\gamma$ are shape parameters. $b$ and $d$ area additional parameters introduced to reduce the complexity of the formula, depend only on $\alpha$ and $\gamma$  (see Minchin 1987).\\
 
Playing with these 5 parameters, different plausible abundance curves can be generated.\\


\subsection {Simulating with Bernoulli}

In order to simulate probabilities of occurrence along the gradient $x$, the parameter $A0$ is replaced by $P0$, the probability of occurrence at the mode.

Thus we get the simulated probability curve, 


$$p(x) = f(x,P0,m,r,\alpha,\gamma)$$\\

and we can simulate presence-absence data $y(x)$ through a Bernoulli distribution with $p(x)$ probabilities of occurrence,

$$y(x) \sim Be(p(x))$$\\


The figure shown an example of different probability curves that can be simulated, along with the corresponding logit transformation (a small quantity has been added to the generated probabilities in order to compute the logit)

\setkeys{Gin}{width=\textwidth}

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=4,width=8>>=
x<-seq(0,100,by=1)

A0<-c(5,4,7,5,9,8)
 m <- c(25,85,40,60,55,60)
 r <- c(3,3,4,4,6,5) * 10
 a <- c(0.1,1,2,4,1.5,1)
 g <- c(0.3,1,2,4,0.5,4)

Ao <- A0 /10

params <- list(m = m, A0 = Ao, r = r, alpha = a, gamma = g)

yp <- coenocline(x, responseModel = "beta",
                params = params,
                countModel = "bernoulli", expectation = TRUE)+1e-6

logityp<-log(yp/(1-yp))+rnorm(length(yp[,1]),0,0)

par(mfrow=c(1,2))
plot(exp(logityp)/(1+exp(logityp)), type = "l", lty = "solid",ylab="p = beta shape",main="Prob + 1e-6",lwd=2)
plot(logityp,type = "l", lty = "solid",ylab="logit(p)",main="logit(Prob + 1e-6)",lwd=2)
@

*In a next step overdispersion will be included, introducing in this process a normal error in the logit scale. In order to obtain presences where the simulated probability is very close to zero, larger deviations for the errors could be set there:\\

$$Ologit(p(x))= logit(p(x))+\epsilon$$

$$\epsilon \sim N(0,sd)$$

$$sd \propto rescale(logit(p(x)))$$

\subsection {Simulating with Poisson}

First, abundance values along the gradient $x$ are generated using the beta function. This abundances are used as mean to simulate new abundances, $ab(x)$, from a Poisson distribution.\\

$$ab(x)\sim Pois(f(x,A0,m,r,a,g))$$\\

If the simulated abundance is zero, it is considered an absence. This way, presence-absence data, $y(x)$, is generated as follows
\begin{eqnarray*}
 && y(x) =\left\{
                \begin{array}{ll}
                    1 & \quad ab(x)>0\\
                    \\
                  0 & \quad ab(x)=0
                \end{array}
              \right.
 \end{eqnarray*}

Thus, the underlying probability of occurrence is

$$ p(x) = 1- P(ab(x)=0) = 1- (f(x,A0,m,r,a,g)^0 e^{-f(x,A0,m,r,a,g)}/0!)=1-e^{-f(x,A0,m,r,a,g)}$$\\

The figure shown an example of different probability curves that can be simulated, along with the corresponding logit transformation.

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=4,width=8>>=
Ao <- c(1,1,2,1,3,2)
params <- list(m = m, A0 = Ao, r = r, alpha = a, gamma = g)


yp <- coenocline(x, responseModel = "beta",
                 params = params,
                 countModel = "poisson", expectation = TRUE)

pay <- coenocline(x, responseModel = "beta", params = params,
                countModel = "poisson")
simpay<-pay
pay[pay>0]<-1

expityp<-(1-dpois(0,yp))+1e-6
logityp<-log(expityp/(1-expityp))

par(mfrow=c(1,2))
#plot(yp, type = "o", lty = "solid",ylab="beta shape abundance",main="expected Abundance")
#plot(simpay, type = "o", lty = "solid",ylab="beta shape abundance",main="sim Pois Abundance")
plot(expityp,type = "l", lty = "solid",ylab="p = 1-dpois(0,abun)",ylim=c(0,1),main="Prob+1e-6",lwd=2)
plot(logityp,type = "l", lty = "solid",ylab="logit(p)",main="logit(p+1e-6)",lwd=2)
@

*In a next step overdispersion will be included.\\

\section {Fitting}

\subsection {Methods}

Up to now 4 methods have been implemented for fitting simulated data:\\


M1- GLM (2$^{nd}$ order polynomial)
<<echo=T, message=FALSE, warning=FALSE, eval=F>>=
reg1<-glm( y~x+I(x^2),data=df,family="binomial")
@ 
M2- GAM with k=10
<<echo=T, message=FALSE, warning=FALSE, eval=F>>=
reg2<-gam(y ~ s(x), family=binomial(link="logit"),data=df)
@ 

M3- GAM with k=3
<<echo=T, message=FALSE, warning=FALSE, eval=F>>=
reg3<-gam(y ~ s(x,k=3), family=binomial(link="logit"),data=df)
@ 
M4- SCAM
<<echo=T, message=FALSE, warning=FALSE, eval=F>>=
reg4<-scam(y ~ s(x,k=5,bs="cv",m=2), family=binomial(link="logit"),data=df)
@ 

\subsection {Measure performance}

Root Mean Squared Error is used as a measure to compare performance between methods (Pya etal. 2014). However, depending on occurrence probability at optima of each curve, errors magnitude are different, so a Relative Root Mean Squared Error is also proposed.\\

Brier`s score is also used in Wood etal. 2016  and has also been implemented.\\


 \begin{eqnarray*}
&&RMSE=\sqrt{\frac{\sum{(p-\hat{p})^2}}{n}}\\
&&RRMSE=\sqrt{\frac{\sum{(p-\hat{p})^2}}{\sum{(\bar{p}-\hat{p})^2}}}\\
&&BrierScore=\frac{\sum{(y-\hat{p})^2}}{n}
 \end{eqnarray*} 
 


\section {Simulated datasets}

In the process of data simulation, the idea is to generate presence-absence data with different underlying characteristics. Different sampling strategies, sample sizes or different probabilities of occurrence at the mode lead to different data. Some preliminary scenarios related with these issues should be defined in order to obtain comparable results.

\subsection {Sampling options}

We assume a range from $r_1$ to $r_2$ of a fake gradient $x$, (if $x<r_1$ or $x>r_2$ the probability of sampling at x is 0) . To sample from this range, several options are proposed:\\

\textbf{1- Uniform Random}: Sample randomly from the whole range giving same probability to all locations.\\

\textbf{2- Sampling probability $\propto$ occurrence probability}: The probability of sampling in a location id proportional to the simulated theoretical occurrence probability. (Note that zero occurrence locations are not sampled.)\\

\textbf{3- Higher sampling probability around the mode}. As an example in this document this options has been implemented as: (there are much more options)
                          
 \begin{eqnarray}
 && \text{probability of sampling at x} =\left\{
                \begin{array}{ll}
                    ps & \quad \text{if } m-r/8 < x < m+r/8\\
                    \\
                  ps/10 & \quad \text{otherwise}
                \end{array}
              \right.
 \end{eqnarray}


\textbf{4- No sampling in an specefic range}. For example:

 \begin{eqnarray}
 && \text{probability of sampling at x} =\left\{
                \begin{array}{ll}
                    ps & \quad \text{if } x < m-r/8\\
                    \\
                  0 & \quad \text{otherwise}
                \end{array}
              \right.
 \end{eqnarray}



\subsection {Occurrence probabilities at optima and sample size}
<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=F,height=4,width=8>>=
load("C:\\Leire\\habitat\\simulation\\doc0\\run.RData")
@


In Michaelis etal. 2017 it is stated that maximum frequencies and sample sizes can affect fitted shapes. Different occurrence probabilities at optima and sample sizes are also proposed and compared to see the effect when fitting the data.\\

\subsection {Dataset 1}

- Objective: See the effect of $P0$ and sample sizes\\

In order to compare the effect of $P0$ and sample size 4 different theoretical curves have been simulated:\\

4 $P0$ proposals: 0.2, 0.46, 0.73, 1 \\

$m$, $\alpha$ and $\gamma$ are fixed to be the same, while $r$ is set as proportional to $P0$ ($r=P0 m$ in this case).\\

3 Sample size proposals: 100, 500, 2000\\


<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=4,width=8>>=
plot(p_real_all,type='l',col=1,lwd=2,main="4 curves",ylab='prob',xlab="grad")
legend("topright",legend=paste0("curve",1:4),lty=1:4,lwd=2)
@

\subsubsection {Simulated PA data}

For this exercise PA (presence-absence) data has been simulated using the Bernouilli distribution for the 4 simulated curves above.\\

The sampling range $[r_1,r_2]$ assumed for each curve has been set as $r_1=(m-rb)-r/3$ and $r_2=(m-rb+r)+r/3$.\\

In the figure below simulated datasets are shown together with the underlying simulated probability curve in the sampled range. Each column represents a curve while each row represents a sampling option. Simulated presence-absence (1-0) data is shown for sample size=500 (a single realization is shown, although 10 simulated dataset have been generated for each case).\\


<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=3,width=6>>=
ggplot(subset(reg,sim<2&mo=="M1"&nsamp==500), aes(grad,jitter(pa),col=curve))+geom_point(size=0.01)+geom_line(aes(grad,real),col=1)+
  facet_grid(nsamp+smp~curve)+theme_bw()+theme(legend.position="none")
@


\subsubsection {Performance measure}

The figure below shows RMSE and RRMSE values from the fitting of each curve (curvei, i=1,...,4) with each method (Mj,j=1,..,4), each sampling option (smpk,k=1,...,4) and each sample size (100, 500, 2000). 10 replicates ave been generated for each case.\\

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=3,width=6>>=

ggplot(subset(SEs,mo!=c("M3","M4")&(smp=="smp1"|smp=="smp2")),aes(curve,log(sqrt(se/nsamp)),fill=curve))+geom_boxplot()+facet_grid(smp~nsamp+mo,scales = "free")+ggtitle("RMSEs")

@

We can observe that RMSE values change depending on the curve (curve1 has lowest $P0$ value and curve 4 highest); higher $P0$ values curves present higher RMSEs. This relation is maintained although RMSE values differ also depending on the sampling size and sampling options.\\


<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=3,width=6>>=
ggplot(subset(SEs,mo!=c("M3","M4")&(smp=="smp1"|smp=="smp2")),aes(curve,log(sqrt(rel_se)),fill=curve))+geom_boxplot()+facet_grid(smp~nsamp+mo,scales = "free")+ggtitle("Relative RMSEs")
@


Relative RMSEs present same behaviour as RMSEs for the first sampling option, while not for the second sampling option where just presence areas are sampled.\\ 

For the sake of simplicity all sampling options and methods are not shown. However we see that different configurations can lead to differences in RMSE or RRMSEs no directly related with the method. For the next simulation exercise same sample size and same occurrence at optima will be fixed.\\


Brier's score seems to perform better for curves with $P0$ values near to 0 or to 1 (not sure if it is valid, need to look more).

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=3,width=6>>=
BRs<-aggregate(bri~mo+sim+curve+smp+nsamp,data=reg,FUN=sum)
ggplot(subset(BRs,mo!=c("M3","M4")&(smp=="smp1"|smp=="smp2")),aes(curve,log(bri/nsamp),fill=curve))+geom_boxplot()+facet_grid(smp~nsamp+mo,scales = "free")+ggtitle("Brier's score")
@


\subsection {Dataset 2}

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=F,height=4,width=8>>=
load("C:\\Leire\\habitat\\simulation\\doc0\\run_2.RData")
@


Different shape parameter have been used to generate this second dataset. Same sample size and same occurrence at optima have been fixed. Then, the four sampling options have been implemented and data has been fitted using the above mentioned 4 methods.

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=4,width=8>>=
plot(p_real_all,type='l',col=1,lwd=2,main="4 curves",ylab='prob',xlab="grad")
legend("topright",legend=paste0("curve",1:4),lty=1:4,lwd=2)
@



<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=3,width=6>>=
ggplot(subset(reg,sim<2&mo=="M1"&nsamp==500), aes(grad,jitter(pa),col=curve))+geom_point(size=0.01)+geom_line(aes(grad,real),col=1)+
  facet_grid(nsamp+smp~curve)+theme_bw()+theme(legend.position="none")
@



<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=6,width=6>>=
ggplot(subset(SEs),aes(mo,log(sqrt(se)/nsamp),fill=curve))+geom_boxplot()+facet_grid(smp~nsamp+curve,scales = "free")+ggtitle("RMSEs")+theme(legend.position="none")

@

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=6,width=6>>=
pred$dif<-pred$pred-pred$pred[-1]
pred$sign<-sign(pred$dif)*sign(c(pred$dif[-1],1))
signs<-aggregate(sign~mo+sim+curve+smp+nsamp,data=subset(pred,grad<98),FUN=function(x){sum(x==-1)})
ggplot(signs,aes(as.factor(mo),sign))+geom_boxplot(aes(fill=curve))+facet_grid(smp~nsamp+curve)+theme(legend.position="none")+ggtitle("Number of Max and Mins")
@


For sample size=100 there are no significant differences between methods in terms of RMSE. When looking at sample size=500 results, M2 (GAM high K) and M4 (SCAM) methods are the ones showing lower RMSEs, except for curve1, which is symmetric and all methods seem to perform similarly. M2 and M4 seem to perform better for all 4 sampling options. However looking at the "Number of Max and Mins" plots, which shows the number maximums and minimums of the predicted probability curve, we see that M2 method leads to values higher than 1 meaning that these shapes do not agree with the ecological niche theory. M4 (SCAM) forces to have a single maximum (at most). \\

In the next subsection data has been simulated with overdispersion as defined in section 2.2. Similar results are found.\\

\subsubsection {Introducing overdispersion}

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=F,height=4,width=8>>=
load("C:\\Leire\\habitat\\simulation\\doc0\\run_2_error.RData")
@



<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=3,width=6>>=
ggplot(subset(reg,sim<2&mo=="M1"&nsamp==500), aes(grad,jitter(pa),col=curve))+geom_point(size=0.01)+geom_line(aes(grad,real),col=1)+
  facet_grid(nsamp+smp~curve)+theme_bw()+theme(legend.position="none")
@



<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=6,width=6>>=
ggplot(subset(SEs),aes(mo,log(sqrt(se)/nsamp),fill=curve))+geom_boxplot()+facet_grid(smp~nsamp+curve,scales = "free")+ggtitle("RMSEs")+theme(legend.position="none")

@

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=6,width=6>>=
pred$dif<-pred$pred-pred$pred[-1]
pred$sign<-sign(pred$dif)*sign(c(pred$dif[-1],1))
signs<-aggregate(sign~mo+sim+curve+smp+nsamp,data=subset(pred,grad<98),FUN=function(x){sum(x==-1)})
ggplot(signs,aes(as.factor(mo),sign))+geom_boxplot(aes(fill=curve))+facet_grid(smp~nsamp+curve)+theme(legend.position="none")+ggtitle("Number of Max and Mins")
@

\subsubsection {Prediction over the whole range $x$}

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=6,width=6>>=
ggplot(subset(pred,sim<2&nsamp>100), aes(grad,pred,col=mo))+geom_point(aes(grad,jitter(pa)),col=8,alpha=0.4,data=subset(reg,sim<2&nsamp>100))+geom_line(size=2,alpha=0.6)+geom_line(aes(grad,real),col=1)+
  facet_grid(smp~nsamp+curve)+theme_bw()
@


\newpage
\section {Application to Sardine Bioman data}

These data has been collected in the Bioman survey, for 6 years (1999, 2002, 2008, 2011, 2014, 2017). Variables used in this study: Presence-absence, SST, SSS and Bathimetry. More variables could be added from online databases.\\

Real data:\\

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=6,width=8>>=
load("C:\\Leire\\Sardina\\datos_mariaS\\BiomData.RData")

reg_res<-function(reg,summ=F,text=0,do.par=1,main=paste(as.character(reg$call)[2])){
  
  if(summ==T){
  print(summary(reg))}
  
  plotmo(reg, level=.95,pt.col=8,do.par=do.par,main=main)
  
 
  
  if(text==1){
  b0 <- reg$coefficients[1]
  b1 <- reg$coefficients[2]
  b2 <- reg$coefficients[3] 
  
  O <<- (-b1)/(2*b2)
  To <<- 1 / sqrt(-2*b2)
  M <<- 1 / (1 + exp(b1^2 / (4 * b2) - b0))
  text(0.3,0.2,paste("Opt=",round(O,2),"Tol=",round(To,2),"Max=",round(M,2)))
  }
}

ggplot(BiomData,aes(x=Longi,y=Lati))+geom_point(aes(col=as.factor(PA)))+facet_wrap(~year)+theme_bw()+ggtitle("Presence/Absence")
@

<<echo=F, message=FALSE, warning=FALSE, eval=F,fig=T,height=6,width=8>>=
ggplot(BiomData,aes(x=Longi,y=Lati))+geom_point(aes(col=Sst))+facet_wrap(~year)+theme_bw()+ggtitle("SST")
@

<<echo=F, message=FALSE, warning=FALSE, eval=F,fig=T,height=6,width=8>>=
ggplot(BiomData,aes(x=Longi,y=Lati))+geom_point(aes(col=Sss))+facet_wrap(~year)+theme_bw()+ggtitle("Sss")
@

<<echo=F, message=FALSE, warning=FALSE, eval=F,fig=T,height=6,width=8>>=
ggplot(BiomData,aes(x=Longi,y=Lati))+geom_point(aes(col=LogBathy))+facet_wrap(~year)+theme_bw()+ggtitle("LogBathy")
@

.\\

Univariate fittings (methods M1 to M4 from left to rigth) for the 3 reponse variables are shown below:\\

\textbf{SSt}

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=2,width=6>>=
par(mfrow=c(1,4))
reg <- glm(PA ~ Sst + I(Sst^2), family=binomial,data=BiomData) 
reg_res(reg,do.par=0,main="GLM")
reg<-gam(PA ~ s(Sst,k=10), family=binomial, data=BiomData, na.rm=T)
reg_res(reg,do.par=0,main="GAM k=10")
reg<-gam(PA ~ s(Sst,k=3), family=binomial, data=BiomData, na.rm=T)
reg_res(reg,do.par=0,main="GAM k=3")
reg<-scam(PA ~ s(Sst,k=5,bs="cv",m=2), family=binomial, data=BiomData)
reg_res(reg,do.par=0,main="SCAM")
@

\textbf{SSs}

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=2,width=6>>=
par(mfrow=c(1,4))
reg <- glm(PA ~ Sss + I(Sss^2), family=binomial,data=BiomData) 
reg_res(reg,do.par=0,main="GLM")
reg<-gam(PA ~ s(Sss,k=10), family=binomial, data=BiomData, na.rm=T)
reg_res(reg,do.par=0,main="GAM k=10")
reg<-gam(PA ~ s(Sss,k=3), family=binomial, data=BiomData, na.rm=T)
reg_res(reg,do.par=0,main="GAM k=3")
reg<-scam(PA ~ s(Sss,k=5,bs="cv",m=2), family=binomial, data=BiomData)
reg_res(reg,do.par=0,main="SCAM")
@

\textbf{Bathimetry}

<<echo=F, message=FALSE, warning=FALSE, eval=T,fig=T,height=2,width=6>>=
par(mfrow=c(1,4))
reg <- glm(PA ~ LogBathy + I(LogBathy^2), family=binomial,data=BiomData) 
reg_res(reg,do.par=0,main="GLM")
reg<-gam(PA ~ s(LogBathy,k=10), family=binomial, data=BiomData, na.rm=T)
reg_res(reg,do.par=0,main="GAM k=10")
reg<-gam(PA ~ s(LogBathy,k=3), family=binomial, data=BiomData, na.rm=T)
reg_res(reg,do.par=0,main="GAM k=3")
reg<-scam(PA ~ s(LogBathy,k=5,bs="cv",m=2), family=binomial, data=BiomData)
reg_res(reg,do.par=0,main="SCAM")
@

For these data GLM, GAM k=3 and SCAM methods give similar results. However, some differences arise: for SST, SCAM gives a concave curve while the rest does not and for Bathimetry SCAM is the only one capturing both tails of a concave curve. In all cases it is clear that results from a GAM with high k are not in concordance with the niche theory.


\end{document}